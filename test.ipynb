{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimates for correlated regressors\n",
    "\n",
    "By JB Poline and Matthew Brett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility with Python 3\n",
    "from __future__ import print_function  # print('me') instead of print 'me'\n",
    "from __future__ import division  # 1/2 == 0.5, not 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array and plotting libraries\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots inside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy print 4 significant digits for prettiness\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random number seed to make random numbers reproducible\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The linear model again\n",
    "\n",
    "We have some vector of data $\\vec{y}$ with values\n",
    "$y_1, y_2, ..., y_N$.\n",
    "\n",
    "We have one or more vectors of regressors\n",
    "$\\vec{x_1}, \\vec{x_2}, ..., \\vec{x_P}$, where $\\vec{x_1}$\n",
    "has values $x_{1,1}, x_{1,2}, ..., x_{1,N}$, and $\\vec{x_p}$\n",
    "has values $x_{p,1}, x_{p,2}, ..., x_{p,N}$.\n",
    "\n",
    "Our linear model says that:\n",
    "\n",
    "$$\n",
    "\\vec{y} = \\beta_1 \\vec{x_1} + \\beta_2 \\vec{x_2} +  ... + \\beta_P \\vec{x_P} + \\vec{\\varepsilon}\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "* $\\beta_1, \\beta_2, ... \\beta_P$ are scaling coefficients for\n",
    "  vectors $\\vec{x_1}, \\vec{x_2}, ..., \\vec{x_P}$ respectively;\n",
    "\n",
    "* $\\vec{\\varepsilon} = \\varepsilon_1, \\varepsilon_2, ... \\varepsilon_N$\n",
    "  are the remaining unexplained errors for each observation.\n",
    "\n",
    "Usually one of vectors $\\vec{x}$ is a vector of constant value 1.\n",
    "This models the intercept of the regression model. We will write this\n",
    "special vector as $\\vec{1}$.\n",
    "\n",
    "As we saw in the [introduction to the general linear\n",
    "model](http://perrin.dynevor.org/glm_intro.html), we can express this\n",
    "same linear model as matrices. We:\n",
    "\n",
    "* assemble the $\\vec{x_p}$ vectors as columns in a design matrix\n",
    "  $\\mathbf{X} = [\\vec{x_1}, \\vec{x_2}, ... \\vec{x_P}]$;\n",
    "\n",
    "* assemble the $\\beta_p$ coefficients into a vector\n",
    "  $\\vec{\\beta} = \\beta_1, \\beta_2, ..., \\beta_P$.\n",
    "\n",
    "Then matrix multiplication does the rest:\n",
    "\n",
    "$$\n",
    "\\vec{y} = \\mathbf{X} \\cdot \\vec{\\beta} + \\vec{\\varepsilon}\n",
    "$$\n",
    "\n",
    "## Models with correlated regressors\n",
    "\n",
    "### Some correlated regressors\n",
    "\n",
    "Imagine we have a TR (image) every 2 seconds, for 30 seconds. Here are\n",
    "the times of the TR onsets, in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(0, 30, 2)\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a hemodynamic response function (HRF) shape for an event\n",
    "starting at time 0. Call this `hrf1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma distribution from scipy\n",
    "from scipy.stats import gamma\n",
    "\n",
    "# Make SPM-like HRF shape with gamma for peak and undershoot\n",
    "hrf1 = gamma.pdf(times, 6) - 0.35 * gamma.pdf(times, 12)\n",
    "# Scale area under curve to 1\n",
    "hrf1 = hrf1 / np.sum(hrf1)\n",
    "# Plot\n",
    "plt.plot(times, hrf1)\n",
    "plt.title('HRF at t=0 (not mean-centered)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make another HRF starting at t=2 (at the beginning of the second\n",
    "TR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HRF starting at t=2\n",
    "hrf2 = np.zeros(hrf1.shape)\n",
    "hrf2[1:] = hrf1[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we remove the mean from these regressors. We do this to\n",
    "make the HRF regressors independent of the mean ($\\vec{1}$)\n",
    "regressor, but it may not be clear yet why that is a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the mean from both HRF regressors\n",
    "hrf1 = (hrf1 - hrf1.mean())\n",
    "hrf2 = (hrf2 - hrf2.mean())\n",
    "plt.plot(times, hrf1, label='hrf1 start t=0')\n",
    "plt.plot(times, hrf2, label='hrf2 start t=2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These `hrf1` and `hrf2` regressors are correlated. The Pearson\n",
    "correlation coefficient between the HRFs is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(hrf1, hrf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some simulated data\n",
    "\n",
    "Now we are going to make some simulated data from the *signal* formed\n",
    "from the correlated regressors, plus some random *noise*.\n",
    "\n",
    "The *signal* comes from the sum of `hrf1` and `hrf2`. This simulates\n",
    "the occurence of two events, one starting at t=0, one at t=2, both\n",
    "causing an HRF response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = hrf1 + hrf2\n",
    "plt.plot(hrf1, label='hrf1')\n",
    "plt.plot(hrf2, label='hrf2')\n",
    "plt.plot(signal, label='signal (combined hrfs)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated data is this signal combined with some random noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(size=times.shape)\n",
    "Y = signal + noise\n",
    "plt.plot(times, signal, label='signal')\n",
    "plt.plot(times, Y, '+', label='signal + noise')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going apply several linear models to these simulated data.\n",
    "\n",
    "All our models include a regressor of a vector of ones, $\\vec{1}$,\n",
    "modeling the mean.\n",
    "\n",
    "We will call our `hrf1` vector $\\vec{h_1}$. Call `hrf2` :\n",
    "$\\vec{h_2}$.\n",
    "\n",
    "Our models are:\n",
    "\n",
    "* A model with $\\vec{x}$ vectors $\\vec{h_1}, \\vec{1}$ -\n",
    "  single HRF model);\n",
    "\n",
    "* A model with $\\vec{h_1}, \\vec{h_2}, \\vec{1}$ - both HRFs model;\n",
    "\n",
    "* A model with $\\vec{h_1}, \\vec{w}, \\vec{1}$, where\n",
    "  $\\vec{w}$ is $\\vec{h_2}$ (`hrf2`) *orthogonalized with\n",
    "  respect to* $\\vec{h_1}$ (`hrf1`). We explain what we mean by\n",
    "  this further down the page.\n",
    "\n",
    "First, the model with $\\vec{h_1}, \\vec{1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design matrix for single HRF model\n",
    "X_s = np.vstack((hrf1, np.ones_like(hrf1))).T\n",
    "plt.imshow(X_s, interpolation='nearest', cmap='gray')\n",
    "plt.title('Model with hrf1 regressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating the effect of noise on parameter estimates\n",
    "\n",
    "Remember that the students-t statistic is:\n",
    "\n",
    "$$\n",
    "t = \\frac{c^T \\hat\\beta}{\\sqrt{\\mathrm{var}(c^T \\hat\\beta)}}\n",
    "$$\n",
    "\n",
    "where $c^T$ is a row vector of contrast weights,\n",
    "$\\hat{\\beta}$ is our vector of estimated parameters, and\n",
    "$\\mathrm{var}(c^T \\hat\\beta)$ is the variance of\n",
    "$c^T \\hat\\beta$.\n",
    "\n",
    "On the assumption of zero mean normally distributed independent noise:\n",
    "\n",
    "$$\n",
    "\\mathrm{var}(c^T \\hat\\beta) = \\hat{\\sigma}^2 c^T (X^T X)^+ c\n",
    "$$\n",
    "\n",
    "where $\\hat{\\sigma}^2$ is our estimate of variance in the\n",
    "residuals, and $(X^T X)^+$ is the\n",
    "[pseudo-inverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_pseudoinverse)\n",
    "of $X^T X$.\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "t = \\frac{c^T \\hat\\beta}{\\sqrt{\\hat{\\sigma}^2 c^T (X^T X)^+ c}}\n",
    "$$\n",
    "\n",
    "We will see that this expection of variance correctly predicts that\n",
    "parameter estimates for correlated regressors will have higher variance\n",
    "for a given level of noise (where the level of noise can be captured by\n",
    "$\\hat{\\sigma}^2$).\n",
    "\n",
    "Put another way, the parameter estimates of correlated regressors are\n",
    "more susceptible to the effect of noise.\n",
    "\n",
    "We can look at the variability of the parameter estimates, by estimating\n",
    "our models on many different simulated data vectors.\n",
    "\n",
    "Each of the data vectors are made of the *signal* (the sum of `hrf1`\n",
    "and `hrf2`) and some *noise*. We take a new sample of noise for each\n",
    "data vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of simulated data vectors in columns\n",
    "n_times = len(times) # number of elements in single data vector\n",
    "n_data_vectors = 100000\n",
    "# Make many noise vectors (new noise for each column)\n",
    "noise_vectors = np.random.normal(size=(n_times, n_data_vectors))\n",
    "# add signal to make data vectors\n",
    "# Use numpy broadcasting to add vector elementwise to 2D array\n",
    "Ys = noise_vectors + signal.reshape(n_times, 1)\n",
    "Ys.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fit the model with only the first HRF regressor to every\n",
    "(signal + noise) sample vector.\n",
    "\n",
    "We will fit our model for each data vector, to make a estimated\n",
    "parameter vector for each data vector. We can stack these estimated\n",
    "parameter vectors into a 2 by `n_data_vectors` array.\n",
    "\n",
    "Call this array $\\beta^s$ (where the $s$ superscript is for\n",
    "the *single* HRF model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit X_one to signals + noise\n",
    "n_regressors = X_s.shape[1]\n",
    "# beta (parameter estimate) matrix, one column per data vector\n",
    "B_s = np.zeros((n_regressors, n_data_vectors))\n",
    "# Estimate the parameters of the model for each data vector\n",
    "X_pinv = npl.pinv(X_s)\n",
    "for i in range(n_data_vectors):\n",
    "    B_s[:, i] = X_pinv.dot(Ys[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, because of the way that matrix multiplications works, we can do\n",
    "exactly the same calculation as we did in the loop above, in one matrix\n",
    "multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_again = X_pinv.dot(Ys)\n",
    "assert np.allclose(B_s, B_again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this trick to estimate the parameter matrices for the rest\n",
    "of our models.\n",
    "\n",
    "Let us look at the variance of the first parameter estimate (the\n",
    "parameter for the `hrf1` regressor).\n",
    "\n",
    "Here is the variance we observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(B_s[0], bins=100)\n",
    "print('Observed B[0] variance for single hrf model:', np.var(B_s[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed B[0] variance for single hrf model: 2.2014181026\n",
    "\n",
    "We can compare the observed variance of the first parameter estimate\n",
    "with that expected from the formula above:\n",
    "\n",
    "$$\n",
    "\\mathrm{var}(c^T \\hat\\beta) = \\hat{\\sigma}^2 c^T (X^T X)^+ c\n",
    "$$\n",
    "\n",
    "To select only the first regressor, we use a contrast vector of\n",
    "\n",
    "$$\n",
    "c = \\left[\n",
    "\\begin{array}{\\cvec}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Our $\\hat{\\sigma}^2$ will be close to 1, because we added noise\n",
    "with variance 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate sigma^2 for every data vector\n",
    "predicted = X_s.dot(B_s)\n",
    "residuals = Ys - predicted\n",
    "# Residuals have N-P degrees of freedom\n",
    "N = n_times\n",
    "P = npl.matrix_rank(X_s) # number of independent columns in design\n",
    "sigma_hat_squared = (residuals ** 2).sum(axis=0) / (N - P)\n",
    "print('Mean sigma^2 estimate:', np.mean(sigma_hat_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean sigma^2 estimate: 1.01981361247\n",
    "\n",
    "Because $\\hat{\\sigma}^2 \\approx 1$,\n",
    "$\\mathrm{var}(c^T \\hat\\beta) \\approx c^T (X^T X)^+ c$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_s = np.array([[1], [0]]) # column vector\n",
    "# c.T{X.T X}+ c\n",
    "C_s.T.dot(npl.pinv(X_s.T.dot(X_s)).dot(C_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the mean of the parameter estimates for\n",
    "$:raw-latex: (`hrf1`), is somewhere above one, even though\n",
    "we only added 1 times the first HRF as the signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observed B[0] mean for single hrf model:', np.mean(B_s[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed B[0] mean for single hrf model: 1.70147967742\n",
    "\n",
    "This is because the single first regresssor has to fit *both*\n",
    "$\\vec{h_1}$ in the signal, and as much as possible of\n",
    "$\\vec{h_2}$ in the signal, because there is nothing else in the\n",
    "model to fit $\\vec{h_2}$.\n",
    "\n",
    "Now let us construct the model with both HRFs as regressors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design matrix for both HRFs model\n",
    "X_b = np.vstack((hrf1, hrf2, np.ones_like(hrf1))).T\n",
    "plt.imshow(X_b, interpolation='nearest', cmap='gray')\n",
    "plt.title('Model with hrf1, hrf2 regressors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will call the resulting 3 by `n_data_vectors` parameter array :\n",
    "$\\beta^b$ (where the $b$ superscript is for *both* HRF\n",
    "regressors).\n",
    "\n",
    "We will use the matrix multiplication trick above to fit all the data\n",
    "vectors at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit X_both to signals + noise\n",
    "B_b = npl.pinv(X_b).dot(Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What estimates do we get for the first regressor, when we have both\n",
    "regressors in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(B_b[0], bins=100)\n",
    "print('Observed B[0] mean for two hrf model', np.mean(B_b[0]))\n",
    "print('Observed B[0] variance for two hrf model', np.var(B_b[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed B[0] mean for two hrf model 1.00299905499\n",
    "Observed B[0] variance for two hrf model 4.35228828591\n",
    "\n",
    "Two things have happened now we added the second (correlated)\n",
    "$\\vec{h_2}$ regressor. First, the mean of the parameter for the\n",
    "$\\vec{h_1}$ regressor has dropped to 1, because\n",
    "$\\beta^b_1 \\vec{h_1}$ is no longer having to model the signal due\n",
    "to $\\vec{h_2}$. Second, the variability of the estimate has\n",
    "increased. This is what the bottom half of the t-statistic predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted variance for hrf1 parameter in both HRF model\n",
    "C_b = np.array([[1], [0], [0]])  # column vector\n",
    "C_b.T.dot(npl.pinv(X_b.T.dot(X_b)).dot(C_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimate of the parameter for $\\vec{h_2}$ has a mean of around\n",
    "1, like the parameter estimates for $\\vec{h_1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(B_b[1], bins=100)\n",
    "print('Observed B[1] mean for two hrf model', np.mean(B_b[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed B[1] mean for two hrf model 0.994534456872\n",
    "\n",
    "This mean of 1 is what we expect because we have\n",
    "$\\vec{h_1} + \\vec{h_2}$ in the signal. Not surprisingly, the\n",
    "$\\vec{h_2}$ parameter estimate has a similar variability to that\n",
    "for the $\\vec{h_1}$ parameter estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observed B[1] variance for two hrf model', np.var(B_b[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed B[1] variance for two hrf model 4.37230501038\n",
    "\n",
    "The observed variance is very similar to the predicted variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_b_1 = np.array([0, 1, 0])[:, None]  # column vector\n",
    "C_b_1.T.dot(npl.pinv(X_b.T.dot(X_b)).dot(C_b_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter estimates for $\\vec{h_1}$ and $\\vec{h_2}$ are\n",
    "anti-correlated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship of estimated parameter of hrf1 and hrf2\n",
    "plt.plot(B_b[0], B_b[1], '.')\n",
    "np.corrcoef(B_b[0], B_b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonalizing hrf2 with respect to hrf1\n",
    "\n",
    "$\\vec{h_2}$ is correlated with $:raw-latex:.\n",
    "\n",
    "We can therefore think of $\\vec{h_2}$ as the sum of some scaling\n",
    "of $\\vec{h_1}$ plus an extra part that cannot be explained by\n",
    "$\\vec{h_1}$.\n",
    "\n",
    "$$\n",
    "\\vec{h_2} = p (\\vec{h_1}) + \\vec{w}\n",
    "$$\n",
    "\n",
    "where $p$ is some scalar, and\n",
    "\n",
    "$$\n",
    "\\vec{w} = \\vec{h_2} - p (\\vec{h_1})\n",
    "$$\n",
    "\n",
    "To restate, we can think of $\\vec{h_2}$ as the sum of some scalar\n",
    "amount of $\\vec{h_1}$ plus $\\vec{w}$.\n",
    "\n",
    "We want to chose $p$ such that\n",
    "$\\vec{w} = \\vec{h_2} - p (\\vec{h_1})$ is orthogonal to\n",
    "$\\vec{h_1}$. In this case $\\vec{w}$ is the part of\n",
    "$\\vec{h_2}$ that cannot be explained by $\\vec{h_1}$.\n",
    "\n",
    "If $\\vec{w}$ is orthogonal to $\\vec{h_1}$ then we call\n",
    "$\\vec{w}$ : $\\vec{h_2}$ *orthogonalized with respect to*\n",
    "$\\vec{h_1}$.\n",
    "\n",
    "Following the same logic as for\n",
    "[projection](http://practical-neuroimaging.github.io/day7.html#key-video-on-projecting-vectors),\n",
    "given $\\vec{w} - p (\\vec{h_1})$ is orthogonal to\n",
    "$\\vec{h_1}$:\n",
    "\n",
    "$$\n",
    "(\\vec{w} - p (\\vec{h_1})) \\cdot \\vec{h_1} = 0 \\implies \\\\\n",
    "\\vec{w} \\cdot \\vec{h_1} - p (\\vec{h_1}) \\cdot \\vec{h_1} = 0 \\implies \\\\\n",
    "\\frac{\\vec{w} \\cdot \\vec{h_1}}{\\vec{h_1} \\cdot \\vec{h_1}} = p\n",
    "$$\n",
    "\n",
    "Put another way, $p (\\vec{h_1})$ such that\n",
    "$\\vec{w} = \\vec{h_2} - p (\\vec{h_1})$ is orthogonal to\n",
    "$\\vec{h_1}$ - is also the projection of $\\vec{h_2}$ onto\n",
    "$\\vec{h_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project hrf2 onto hrf1\n",
    "p = hrf2.dot(hrf1) / hrf1.dot(hrf1)\n",
    "projection = p * hrf1\n",
    "# Get \\vec{w}\n",
    "w = hrf2 - projection\n",
    "# w and hrf1 are now orthogonal\n",
    "assert np.allclose(w.dot(hrf1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the vector parts\n",
    "plt.plot(times, hrf1, label=r'$\\vec{h_1}$')\n",
    "plt.plot(times, hrf2, label=r'$\\vec{h_2}$')\n",
    "plt.plot(times, projection, label=r'$p (\\vec{h_1})$')\n",
    "plt.plot(times, w, label=r'$\\vec{w}$')\n",
    "plt.legend()\n",
    "# hrf1 part of hrf2, plus unique part, equals original hrf2\n",
    "assert np.allclose(hrf2, projection + w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of the first regressor did we find in the second regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us rewrite our original model containing `hrf1, hrf2`:\n",
    "\n",
    "$$\n",
    "\\vec{y} = \\beta^b_1 \\vec{h_1} + \\beta^b_2 \\vec{h_2} + \\beta^b_3 1\n",
    "$$\n",
    "\n",
    "where $\\vec{y}$ is our data vector.\n",
    "\n",
    "Now we know we can also write this as:\n",
    "\n",
    "$$\n",
    "\\vec{y} = \\beta^b_1 \\vec{h_1} +\n",
    "  \\beta^b_2 (p (\\vec{h_1}) + \\vec{w}) + \\beta^b_3 1 \\\\\n",
    "= \\beta^b_1 \\vec{h_1} +\n",
    "  \\beta^b_2 p (\\vec{h_1}) + \\beta^b_2 \\vec{w} + \\beta^b_3 1 \\\\\n",
    "= (\\beta^b_1 + p \\beta^b_2) \\vec{h_1} + \\beta^b_2 \\vec{w} + \\beta^b_3 1\n",
    "$$\n",
    "\n",
    "So, what will happen if we drop $\\vec{h_2}$ from our model and\n",
    "leave only $\\vec{w}$?\n",
    "\n",
    "We have called the parameters from the model with\n",
    "$\\vec{h_1}, \\vec{h_2}$ : $\\beta^b$. Call the parameters from\n",
    "the model with $\\vec{h_1}, \\vec{w}$ : $\\beta^w$.\n",
    "\n",
    "We can see that we are going to get the exact same fit to the data with\n",
    "these two models if $\\beta^w_2 = \\beta^b_2$ and\n",
    "$\\beta^w_1 = p \\beta^b_2 + \\beta^b_1$.\n",
    "\n",
    "Let us try this new model and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w = np.vstack((hrf1, w, np.ones_like(hrf1))).T\n",
    "plt.imshow(X_w, interpolation='nearest', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "B_w = npl.pinv(X_w).dot(Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first look at the distribution of $\\beta^w_1$\n",
    "`== B_w[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of parameter for hrf1 in orth model\n",
    "plt.hist(B_w[0], bins=100)\n",
    "print('Observed B[0] mean for two hrf orth model',\n",
    "      np.mean(B_w[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed B[0] mean for two hrf orth model 1.70147967742\n",
    "\n",
    "Notice that $\\beta^w_1$ now has the same values as for the single\n",
    "HRF model : $\\beta^s_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(B_s[0, :], B_w[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It therefore has the same variance, and the predicted variance matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observed B[0] variance for two hrf orth model', np.var(B_w[0]))\n",
    "pred_var = C_b.T.dot(npl.pinv(X_w.T.dot(X_w)).dot(C_b))\n",
    "print('Predicted B[0] variance for two hrf orth model', pred_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed B[0] variance for two hrf orth model 2.2014181026\n",
    "Predicted B[0] variance for two hrf orth model [[ 2.2051]]\n",
    "\n",
    "The fact that the single hrf and orthogonalized model parameters match\n",
    "may make sense when we remember that adding the $\\vec{w}$\n",
    "regressor to the model cannot change the parameter for the\n",
    "$\\vec{h_1}$ regressor as $\\vec{w}$ is orthogonal to\n",
    "$\\vec{h_1}$.\n",
    "\n",
    "We predicted above that $\\beta^w_2$ would stay the same as\n",
    "$\\beta^b_2$ from the not-orthogonalized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(B_b[1, :], B_w[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predicted that $\\beta^w_1$ would become\n",
    "$\\beta^b_1 + p \\beta^b_2$ from the not-orthogonalized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_beta1 = B_b[0, :] + p * B_b[1, :]\n",
    "assert np.allclose(predicted_beta1, B_w[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictions were correct. So let us revise what happened:\n",
    "\n",
    "* We estimated our original model with correlated\n",
    "  $\\vec{h_1}, \\vec{h_2}$ to get corresponding estimated\n",
    "  parameters $\\beta^b_1, \\beta^b_2$;\n",
    "\n",
    "* we orthogonalized $\\vec{h_2}$ with respect to $\\vec{h_1}$\n",
    "  to give $p$ and $\\vec{w}$;\n",
    "\n",
    "* we replaced $\\vec{h_2}$ with $\\vec{w}$ in the model, and\n",
    "  re-estimated, giving new parameters $\\beta^w_1$ for\n",
    "  $\\vec{h_1}$, $\\beta^w_2$ for $\\vec{w}$;\n",
    "\n",
    "* $\\beta^w_2 = \\beta^b_2$ - the parameter for the new\n",
    "  orthogonalized regressor is unchanged from the non-orthogonalized\n",
    "  case;\n",
    "\n",
    "* $\\beta^w_1 = \\beta^b_1 + p \\beta^b_2$ - the parameter for the\n",
    "  *unchanged* regressor has increased by $\\beta^b_2$ times the\n",
    "  amount of $\\vec{h_2}$ present in $\\vec{h_1}$.\n",
    "\n",
    "Here we show some example parameters from the three model fits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters from the single hrf model\n",
    "B_s[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters from the non-orth two-hrf model\n",
    "B_b[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters from the orth model\n",
    "B_w[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter for the hrf1 regressor in the non-orth model\n",
    "# is correlated with the parameter for the hrf1 regressor\n",
    "# in the orth model.\n",
    "plt.plot(B_b[0], B_w[0], '.')\n",
    "plt.title('Orth and non-orth hrf1 parameters correlate')\n",
    "np.corrcoef(B_b[0], B_w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship of estimated parameters for hrf1 and orthogonalized hrf2\n",
    "# (they should be independent)\n",
    "plt.plot(B_w[0], B_w[1], '+')\n",
    "plt.title('hrf1 and orth hrf2 parameters are independent')\n",
    "np.corrcoef(B_w[0], B_w[1])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}